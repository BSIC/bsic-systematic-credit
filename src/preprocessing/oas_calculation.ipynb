{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **OUTDATED** - Look at `oas_calculation_polars`"
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "7958d4a9",
    "execution_start": 1713636401514,
    "execution_millis": 4171,
    "deepnote_to_be_reexecuted": false,
    "cell_id": "826a5b5fc1b4420fafc7f1f55421ac45",
    "deepnote_cell_type": "code"
   },
   "source": "!pip install -r ../requirements.txt",
   "block_group": "04dfea0dfed241cea8f2be5ac1d2d7df",
   "outputs_reference": "s3:deepnote-cell-outputs-production/62613e20-7b8f-4dd3-852c-5c80ee5c62f3",
   "content_dependencies": null,
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "50693380",
    "execution_start": 1713636405696,
    "execution_millis": 183,
    "deepnote_to_be_reexecuted": false,
    "cell_id": "ce2dc4ce959946c6a66ca0f6c3b71931",
    "deepnote_cell_type": "code"
   },
   "source": [
    "import pandas as pd\n",
    "import QuantLib as ql\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from typing import Literal\n",
    "import math\n",
    "import warnings\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 50)"
   ],
   "block_group": "c8d92469db31480d8b485f671d3cc160",
   "outputs_reference": null,
   "content_dependencies": null,
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "formattedRanges": [],
    "cell_id": "c54177e5579d40e6a9d562efd813694a",
    "deepnote_cell_type": "text-cell-h1"
   },
   "source": "# Load Bond Returns data and Zero Rate Curve",
   "block_group": "1505f3285a0744ed85e2a44e9a3af107"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Bond Returns + Data Cleaning"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "5a868aabd0b44dc8abff0321bdffb9ef",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "For the definitions of the features, refer to the pdf in the `docs` folder\n",
    "\n",
    "Variable Summary: \n",
    "\n",
    "* `cs`: credit spread computed as bond_yield in excess of duration-matched portfolio of US Treasuries yields\n",
    "* `tmt`: time to maturity (in months, I guess)\n",
    "* `ind_num_17`: Fama-French 17 Industry Classification (may be useful for value factor)\n",
    "* `size_ig`, `size_jk`: dummy for (respectively) IG/HY bonds in the BAML/ICE index\n",
    "* `bond_type`: US Corporate Convertible (CCOV), US Corporate Debentures (CDEB), US Corporate Medium Term Note (CMTN), US Corporate Medium Term Note Zero (CMTZ), or US Corporate Paper (CP)\n",
    "* `R_FR`, `N_FR` and co.: rating as names and one-hot encoded, probably from different providers (SP may be S&P, FR Fitch Ratings, MR Moody's\n",
    "* `INTEREST_FREQUENCY`: e.g. 13 for variable coupon, -1 for NA, 14 for bi-monthly, 15-16 undocumented\n",
    "* `DATED_DATE`: date from which the bond interest accrues\n",
    "* Additional Info on variables: FISD data dictionary 2012 document\n",
    "\n",
    "Prices Variables\n",
    "\n",
    "* `PRICE_EOM`: considers all trading days and takes the last\n",
    "* `PRICE_LDM`: consider only last trading day of the month otherwise NaN\n",
    "* `PRICE_L5M`: consider only last 5 trading days of the month otherwise NaN\n",
    "* `T_SPREAD`: average trade-weighted bid-ask spread\n",
    "* `T_YLD_PT`: average trade-weighted yield point\n",
    "* `T_VOLUME`: volume traded during the month, par-value\n",
    "* `T_DVOLUME`: volume traded during the month, dollar value\n",
    "* `bondprc` is adjusted for MMN, `BONDPRC` is unadjusted\n",
    "\n",
    "Other notes\n",
    "\n",
    "* We may want to remove defaulted bonds (check if they were actually already removed)"
   ],
   "block_group": "d647787c3090446690a2090286b3cbdf"
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "7321b315",
    "execution_start": 1713635584941,
    "execution_millis": 4832,
    "sql_integration_id": "deepnote-dataframe-sql",
    "deepnote_variable_name": "bond_data",
    "deepnote_to_be_reexecuted": false,
    "cell_id": "f49c28841be94cc4813865191a239c55",
    "deepnote_cell_type": "sql",
    "deepnote_sql_source": "SELECT * \nFROM '/work/data/bond_data_final.csv'\nLIMIT 1000"
   },
   "source": [
    "date_cols = [\n",
    "    'date', \n",
    "    'MATURITY',\n",
    "    'OFFERING_DATE', \n",
    "    'FIRST_INTEREST_DATE', \n",
    "    'LAST_INTEREST_DATE',\n",
    "    'nextcoup',\n",
    "    'DEFAULT_DATE',\n",
    "    'REINSTATED_DATE',\n",
    "    'DATED_DATE'\n",
    "]\n",
    "\n",
    "bond_data = pd.read_csv('../data/bond_data_final.csv', index_col=0, parse_dates=date_cols)\n",
    "\n",
    "bond_data.iloc[:2,:10]"
   ],
   "block_group": "8b24d105bf90471cbe6ae408caad5883",
   "outputs_reference": "s3:deepnote-cell-outputs-production/691be501-ea86-4bd6-8383-977aad71ce61",
   "content_dependencies": null,
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# merge duration across the two dataframes\n",
    "bond_data['duration'] = bond_data['DURATION_y'].fillna(bond_data['DURATION_x'])\n",
    "bond_data.drop(['DURATION_x', 'DURATION_y'], axis=1, inplace=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "useless_cols = [\n",
    "    'company_symbol', # we do not need it\n",
    "    'TREASURY_MATURITY', # we do not need it\n",
    "    'CONV', # convertible bonds (we already removed all convertibles) \n",
    "    'sic_code', # SIC Industry Code (we don't need it) \n",
    "    'mom6_1', # 6m momentum (we don't need it) \n",
    "    'ltrev48_12', # sum of bond returns over 48months (momentum) \n",
    "    'TMT', # time to maturity in years (we have it in months in tmt) and TMT has NaNs while tmt does not\n",
    "    'DATE', # has NaNs while date does not\n",
    "    'CUSIP', # has Nans while cusip does not\n",
    "    'COUPON', # repeated in coupon and COUPON has NaNs while coupon does not\n",
    "]\n",
    "\n",
    "bond_data.drop(useless_cols, axis=1, inplace=True, errors='ignore')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# fill all DATED_DATE, OFFERING_DATE, MATURITY, and DAY_COUNT_BASIS since they are all the same for each issue\n",
    "cols_to_fill = ['DATED_DATE', 'OFFERING_DATE', 'DAY_COUNT_BASIS', 'MATURITY', 'NCOUPS']\n",
    "grouped = bond_data.groupby('cusip')\n",
    "def fill_dates(group): \n",
    "    group[cols_to_fill] = group[cols_to_fill].ffill().bfill()\n",
    "    return group \n",
    "\n",
    "filled_data = grouped.apply(fill_dates, include_groups=False)\n",
    "bond_data = filled_data.reset_index(0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# remove the CUSIPS for which there is no DATED_DATE, OFFERING_DATE and DAY COUNT BASIS? we should probably do that\n",
    "new_bond_data = bond_data.dropna(subset=cols_to_fill)\n",
    "\n",
    "removed_cusips = bond_data['cusip'].nunique() - new_bond_data['cusip'].nunique()\n",
    "bond_data = new_bond_data\n",
    "\n",
    "print(f'Removed {removed_cusips} CUSIPs from the DataFrame')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "required_cols = ['coupon', 'date'] + cols_to_fill\n",
    "\n",
    "bond_data[required_cols].isna().sum()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Great, now we have all variables needed for the analysis!"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "formattedRanges": [],
    "cell_id": "1e6b94406af04aa5bb9f172b15df2fc6",
    "deepnote_cell_type": "text-cell-h1"
   },
   "source": "# Load the historical zero curve",
   "block_group": "f17c1c52563443a9bc36820fce72448b"
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "8f44720e",
    "execution_start": 1713636079206,
    "execution_millis": 1574,
    "deepnote_to_be_reexecuted": false,
    "cell_id": "a4c3fca0247f402185a036a18eb5dd45",
    "deepnote_cell_type": "code"
   },
   "source": [
    "yield_curve = pd.read_csv('../data/yield_panel_monthly_frequency_daily_maturity.csv', index_col=0)\n",
    "yield_curve.index = pd.to_datetime(yield_curve.index)\n",
    "yield_curve.drop('MAX_DATA_TTM', axis=1, inplace=True)  "
   ],
   "block_group": "1ab17150e7fa4c7c96c90a3ba349f33f",
   "outputs_reference": null,
   "content_dependencies": null,
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "yield_curve.dtypes",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "yield_curve = yield_curve.resample('ME').last()\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "27654e10",
    "execution_start": 1713636083565,
    "execution_millis": 505,
    "deepnote_to_be_reexecuted": false,
    "cell_id": "ab371d23bfde4c28acc515e4b4ae8a79",
    "deepnote_cell_type": "code"
   },
   "source": "yield_curve.iloc[:10, :10]",
   "block_group": "70d083385b55476482503a1ccfbd2bc1",
   "outputs_reference": "s3:deepnote-cell-outputs-production/f853e758-830b-489a-86d6-887dc1710353",
   "content_dependencies": null,
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "formattedRanges": [],
    "cell_id": "ffc03bdcc0944eb7b22f8df758d70d48",
    "deepnote_cell_type": "text-cell-h1"
   },
   "source": "# OAS Calculation with QuantLib",
   "block_group": "f9d46ba3e10e4e7bb9b560ab8b2c0be0"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "03cb3458ae914d10b6cbddaf90d8d623",
    "deepnote_cell_type": "markdown"
   },
   "source": "OAS is the spread that added to the zero rates in the pricing function returns the price of the bond. We use the Newton method to get a solution for the OAS. In our case, since we stripped bonds with optionality, the OAS is the Z-Spread",
   "block_group": "21e488e742ae4cedbb90e17aeb74885b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mask = (bond_data['tmt'] / 12) < 30\n",
    "\n",
    "bond_data[mask].shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "bond_data[mask].shape[0] / bond_data.shape[0]",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "bond_data = bond_data[mask]",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "bond_data['bondprc'].isna().sum() / bond_data.shape[0]",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "7c1ccb04",
    "execution_start": 1713635686207,
    "execution_millis": 120,
    "deepnote_to_be_reexecuted": false,
    "cell_id": "5258ddb1910a466abe9b44028da968e7",
    "deepnote_cell_type": "code"
   },
   "source": [
    "mask_bond = (bond_data['cusip'] == '00103YAE1') &(bond_data['date'] == '2002-08-31') \n",
    "example_bond = bond_data.loc[mask_bond].iloc[0] \n",
    "\n",
    "example_bond[:5]"
   ],
   "block_group": "ee69ad1a5a214fa38ecc6d7e413c01c1",
   "outputs_reference": "dbtable:cell_outputs/a57ee1b6-4c80-460c-aae4-16507966910e",
   "content_dependencies": null,
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "bond_data[bond_data['bondprc'] < 2]",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mask = bond_data['NCOUPS'] > 0\n",
    "bond_data[mask]['cusip'].nunique() / bond_data['cusip'].nunique()\n",
    "\n",
    "bond_data = bond_data[mask]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "example_bond.DAY_COUNT_BASIS",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "8.54 / 4 /100 * 100",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "bbbe6c0",
    "execution_start": 1713636231947,
    "execution_millis": 0,
    "deepnote_to_be_reexecuted": false,
    "cell_id": "2a111d66f1c4474ab4439349b2d6c7d8",
    "deepnote_cell_type": "code"
   },
   "source": "bond_data.columns",
   "block_group": "0f605f3e2efd43469a3afcc87b412691",
   "outputs_reference": "dbtable:cell_outputs/31f444fa-61f6-4dd6-8767-06b4ddd600c7",
   "content_dependencies": null,
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "bond_data['DAY_COUNT_BASIS'].unique()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def decompose_date(date: pd.Timestamp):\n",
    "    \"\"\"\n",
    "    Returns day, month, year given a `pd.Timestamp`\n",
    "    Parameters\n",
    "    ----------\n",
    "    date: pd.Timestamp\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple[int, int, int]: day, month, year\n",
    "\n",
    "    \"\"\"\n",
    "    return date.day, date.month, date.year\n",
    "\n",
    "def get_day_count(bond: pd.Series): \n",
    "    day_count_convention = bond.DAY_COUNT_BASIS\n",
    "    \n",
    "    if day_count_convention == '30/360': \n",
    "        return ql.Thirty360(ql.Thirty360.USA)\n",
    "    elif day_count_convention == 'ACT/360': \n",
    "        return ql.Actual360()\n",
    "    elif day_count_convention == 'ACT/ACT': \n",
    "        return ql.ActualActual(ql.ActualActual.Bond)\n",
    "    \n",
    "    raise Exception(f'we did not implement day count {day_count_convention}')\n",
    "    \n",
    "def get_coupon_freq(bond: pd.Series): \n",
    "    coupon_freq = bond.NCOUPS\n",
    "    if coupon_freq == 1: \n",
    "        return ql.Period(ql.Annual)\n",
    "    elif coupon_freq == 2: \n",
    "        return ql.Period(ql.Semiannual)\n",
    "    elif coupon_freq == 4: \n",
    "        return ql.Period(ql.Quarterly)\n",
    "    elif coupon_freq == 12: \n",
    "        return ql.Period(ql.Monthly)\n",
    "    \n",
    "    raise Exception(f'we did not implement coupon freq {coupon_freq}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "e7f8963",
    "execution_start": 1713635912409,
    "execution_millis": 81,
    "deepnote_to_be_reexecuted": false,
    "cell_id": "115bf260678f4c5cb90b2f8657a0989e",
    "deepnote_cell_type": "code"
   },
   "source": [
    "\n",
    "def get_zero_curve(date: ql.Date, calendar: ql.Calendar, maturity_freq: Literal['daily', 'monthly']) -> ql.ZeroCurve: \n",
    "    # get the zero rates for that specific date\n",
    "    date_mask = pd.to_datetime(date.to_date())\n",
    "    zero_rates = yield_curve.loc[date_mask]\n",
    "    zero_rates: pd.Series\n",
    "    \n",
    "    # create the list of tenors based on the number of observations\n",
    "    tenors = np.arange(0, len(zero_rates) + 1)\n",
    "    \n",
    "    # set the tenor unit and compounding frequency based on the type of data used\n",
    "    if maturity_freq == 'daily':\n",
    "        tenor_unit = ql.Days\n",
    "        compounding_freq = ql.Daily\n",
    "    elif maturity_freq == 'monthly': \n",
    "        tenor_unit = ql.Months\n",
    "        compounding_freq = ql.Monthly\n",
    "    else: \n",
    "        raise Exception(f'maturity not valid')\n",
    "    \n",
    "    # create the list of spot dates and rates\n",
    "    #   (need to add a point for the evaluation date, hence the 0.)\n",
    "    spot_dates = [date + ql.Period(tenor.item(), tenor_unit) for tenor in tenors] \n",
    "    spot_rates = [0.] + zero_rates.to_list()\n",
    "    \n",
    "    # set payment convention as specified in the paper (365 days)\n",
    "    pmt_convention = ql.Actual365Fixed(ql.Actual365Fixed.Standard)\n",
    "    \n",
    "    # create the ZeroCurve and return it\n",
    "    calendar = ql.UnitedStates(ql.UnitedStates.SOFR)\n",
    "    spot_curve = ql.ZeroCurve(spot_dates, spot_rates, pmt_convention, calendar, ql.Linear(), ql.Compounded, ql.Continuous)\n",
    "    \n",
    "    return spot_curve\n",
    "\n",
    "def debug_cashflows(bond: ql.FixedRateBond, bond_data: pd.Series, mkt_price: float, z_spread: float, impl_clean_price: float):\n",
    "    \"\"\"\n",
    "    Debug cashflows given a bond and bond_data. \n",
    "    \n",
    "    Function to debug the results of the OAS calcuations.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    bond\n",
    "    bond_data\n",
    "    \"\"\"\n",
    "    cashflows = bond.cashflows()\n",
    "    print('--- BOND SETUP & CALCS CHECKS ---')\n",
    "    print(f'\\tCalc Date = {bond_data.date}, \\n\\tOffering date = {bond_data.OFFERING_DATE}, Maturity = {bond_data.MATURITY}')\n",
    "    \n",
    "    # check for coupon_amt\n",
    "    data_coupon_amt = bond_data.coupon * 100 / bond_data.NCOUPS / 100 # todo account for the coupon frequency\n",
    "    bond_ql_coup_amt = np.round(cashflows[2].amount(), 2)\n",
    "    print(f'\\tCoupon Check: Data = {data_coupon_amt}, Model = {bond_ql_coup_amt}')\n",
    "        \n",
    "    # check that Accrued Interest\n",
    "    data_accrued_interest = bond_data.COUPACC\n",
    "    bond_ql_accr_interest = np.round(bond.dirtyPrice() - bond.cleanPrice(), 2)\n",
    "    print(f'\\tAccrued Interest Check: Data = {data_accrued_interest}, Model = {bond_ql_accr_interest}')\n",
    "    \n",
    "    print('\\tCASHFLOWS SCHEDULE')\n",
    "    for c in cashflows:\n",
    "        print('\\t%20s %12f' % (c.date(), c.amount()))\n",
    "        \n",
    "    coupons = [ql.as_coupon(c) for c in bond.cashflows()[:-1]]\n",
    "    coupons_df = pd.DataFrame([(c.date().to_date(), c.rate(), c.accrualPeriod()) for c in coupons], columns=['date', 'rate', 'accrual_period'], index=range(1,len(coupons)+1))\n",
    "    print(coupons_df)\n",
    "    \n",
    "    # checks for coupon dates\n",
    "    bond_first_pmt_date = bond_data.FIRST_INTEREST_DATE.date()\n",
    "    bond_last_pmt_date = bond_data.LAST_INTEREST_DATE.date()\n",
    "    bond_ql_first_pmt_date = cashflows[0].date().to_date()\n",
    "    bond_ql_last_pmt_date = cashflows[-3].date().to_date()\n",
    "    \n",
    "    first_delta = (bond_first_pmt_date - bond_ql_first_pmt_date).days\n",
    "    last_delta = (bond_last_pmt_date - bond_ql_last_pmt_date).days\n",
    "    \n",
    "    print('\\tChecks for Payment Dates')\n",
    "    print(f'\\t\\tFirst pmt: Data = {bond_first_pmt_date}, Model = {bond_ql_first_pmt_date}, Delta = {first_delta}')\n",
    "    print(f'\\t\\tLast pmt: Data = {bond_last_pmt_date}, Model = {bond_ql_last_pmt_date}, Delta = {last_delta}')\n",
    "    \n",
    "    \n",
    "    delta_p = mkt_price - impl_clean_price\n",
    "    delta_bps = delta_p / mkt_price * 100 * 100\n",
    "\n",
    "    print(f'\\tZ-SPREAD = {z_spread:.5f} ({z_spread * 100:.3f}%)')\n",
    "    print(f'\\tMkt Price = {mkt_price}, Implied Clean Price = {impl_clean_price:.5f}, Delta = {delta_p:.5f}, Delta (bps): {delta_bps:.2f}')\n",
    "    \n",
    "    print(f'DEBUG: {data_coupon_amt} {bond_ql_coup_amt}')\n",
    "    assert math.isclose(data_coupon_amt, bond_ql_coup_amt, rel_tol=1e-2)\n",
    "    if not math.isclose(data_accrued_interest, bond_ql_accr_interest): \n",
    "        warnings.warn('Accrued Interest is not correct')\n",
    "    # assert math.isclose(data_accrued_interest, bond_ql_accr_interest) \n",
    "    assert bond_first_pmt_date == bond_ql_first_pmt_date # check the first payment date matches\n",
    "    print('--- ALL CHECKS PASSED FOR BOND CALCULATIONS ---')\n",
    "    print('--- CHECKS FOR Z-SPREAD CALCULATIONS ---')\n",
    "    assert abs(first_delta) < 3\n",
    "    assert abs(last_delta) < 3\n",
    "    # delta p less than 1bp\n",
    "    assert abs(delta_p) < 0.05\n",
    "    print('--- ALL CHECKS PASSED FOR Z-SPREAD CALCULATION ---')\n",
    "    \n",
    "class ParameterNaNException(Exception):\n",
    "    def __init__(self, varname: str):\n",
    "        self.msg = f'Variable {varname} is NaN, and it is required.'\n",
    "        super().__init__(self.msg)\n",
    "        \n",
    "def check_parameters(bond: pd.Series): \n",
    "    for varname in ['coupon', 'principal_amt']: \n",
    "        if np.isnan(bond[varname]): raise ParameterNaNException(varname)\n",
    "    \n",
    "    for varname in ['date', 'OFFERING_DATE', 'MATURITY', 'DATED_DATE']: \n",
    "        if pd.isnull(bond[varname]): raise ParameterNaNException(varname)\n",
    "    \n",
    "def compute_OAS(bond: pd.Series, debug: bool = False):\n",
    "    # check that parameters are defined\n",
    "    print(f'computing OAS for bond {bond.cusip} at {bond.date.date()}...', end='')\n",
    "    if np.isnan(bond.bondprc): \n",
    "        print('No price data, skipping this row')\n",
    "        return np.nan\n",
    "    check_parameters(bond)\n",
    "    \n",
    "    calc_date = ql.Date(*decompose_date(bond.date))\n",
    "    ql.Settings.instance().evaluationDate = calc_date\n",
    "    \n",
    "    # key data\n",
    "    calendar = ql.UnitedStates(ql.UnitedStates.NYSE) # calendar to follow for calculations\n",
    "    calendar = ql.NullCalendar()\n",
    "    day_count_convention = get_day_count(bond) # the day count convention as specified in the bond\n",
    "    day_count_convention = ql.ActualActual(ql.ActualActual.Bond) # the day count convention as specified in the bond\n",
    "    \n",
    "    # bond data\n",
    "    issue_date = ql.Date(*decompose_date(bond.OFFERING_DATE))\n",
    "    accruing_start_date = ql.Date(*decompose_date(bond.DATED_DATE)) # this is the date from which the bond starts accruing interest\n",
    "    maturity_date = ql.Date(*decompose_date(bond.MATURITY))\n",
    "    tenor = get_coupon_freq(bond)\n",
    "    date_generation = ql.DateGeneration.Backward\n",
    "    month_end = False\n",
    "    face_value = bond.principal_amt\n",
    "    face_value = 100\n",
    "    coupon = bond.coupon / 100\n",
    "    mkt_price = bond.bondprc\n",
    "    first_pmt_date = ql.Date(*decompose_date(bond.FIRST_INTEREST_DATE))\n",
    "    \n",
    "    schedule = ql.Schedule(accruing_start_date, maturity_date, tenor, calendar, ql.Unadjusted, ql.Unadjusted, date_generation, month_end, first_pmt_date)\n",
    "    \n",
    "    settlement_days = 0\n",
    "    \n",
    "    # zero curve\n",
    "    spot_curve = get_zero_curve(calc_date, calendar, 'daily')\n",
    "    pricing_curve = ql.YieldTermStructureHandle(spot_curve)\n",
    "    \n",
    "    bond_ql = ql.FixedRateBond(\n",
    "        settlement_days, \n",
    "        face_value, \n",
    "        schedule, \n",
    "        [coupon],\n",
    "        day_count_convention\n",
    "    )\n",
    "    bond_ql.setPricingEngine(ql.DiscountingBondEngine(pricing_curve))\n",
    "    \n",
    "    # Z-spread calculation \n",
    "    z_spread = ql.BondFunctions.zSpread(\n",
    "        bond_ql, \n",
    "        mkt_price,\n",
    "        spot_curve,\n",
    "        day_count_convention, \n",
    "        ql.Compounded,\n",
    "        ql.Continuous, \n",
    "        calc_date,\n",
    "        1.e-16,\n",
    "        10_000_000,\n",
    "        0.\n",
    "    )\n",
    "    \n",
    "    def get_impl_clean_price(spread):\n",
    "        spread1 = ql.SimpleQuote(spread)\n",
    "        spread_handle1 = ql.QuoteHandle(spread1)\n",
    "        ts_spreaded1 = ql.ZeroSpreadedTermStructure(pricing_curve,\n",
    "                                                    spread_handle1,\n",
    "                                                    ql.Compounded,\n",
    "                                                    ql.Continuous)\n",
    "        ts_spreaded_handle1 = ql.YieldTermStructureHandle(ts_spreaded1)\n",
    "        fixed_rate_bond = ql.FixedRateBond(settlement_days,\n",
    "                                        face_value,\n",
    "                                        schedule,\n",
    "                                        [coupon],\n",
    "                                        day_count_convention)\n",
    "        # Set Valuation engine\n",
    "        bond_engine = ql.DiscountingBondEngine(ts_spreaded_handle1)\n",
    "        fixed_rate_bond.setPricingEngine(bond_engine)\n",
    "        value = fixed_rate_bond.cleanPrice()\n",
    "        print(f'bond NPV: {fixed_rate_bond.NPV()}, clean: {fixed_rate_bond.cleanPrice()}')\n",
    "        return value\n",
    "    \n",
    "    if debug: \n",
    "        impl_clean_price = get_impl_clean_price(z_spread)\n",
    "        debug_cashflows(bond_ql, bond, mkt_price, z_spread, impl_clean_price)\n",
    "        \n",
    "    print(f' ...Z-spread is {z_spread}')\n",
    "\n",
    "    return z_spread"
   ],
   "block_group": "694a69b778c449628414f12500f10b77",
   "outputs_reference": null,
   "content_dependencies": null,
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "b6c11a54",
    "execution_start": 1713635920962,
    "execution_millis": 106,
    "deepnote_to_be_reexecuted": false,
    "cell_id": "7a74ec40beb94d12abba0f65aa333c17",
    "deepnote_cell_type": "code"
   },
   "source": "spot_crv = compute_OAS(example_bond)",
   "block_group": "9a921ee166384369a114b5d10438ea89",
   "outputs_reference": null,
   "content_dependencies": null,
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "bond_data.sort_values(['date', 'cusip'], inplace=True)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "bond_data[bond_data['date'] == '2002-8-31']",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "OAS = bond_data.apply(compute_OAS, axis=1)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "OAS.head()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_yc(date, curve: ql.ZeroCurve = None): \n",
    "    date_mask = date\n",
    "    zero_rates = yield_curve.loc[date_mask]\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    dates, rates = zip(*curve.nodes())\n",
    "    dates = [d.to_date() for d in dates]\n",
    "    \n",
    "    print(dates[:3])\n",
    "    print(rates[:3])\n",
    "    \n",
    "    ax.plot(dates[1:], zero_rates, lw='5')\n",
    "    ax.plot(dates, rates, c='red')\n",
    "    \n",
    "plot_yc('2012-04-30', spot_crv)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=809bdc60-6cc4-4659-aae8-7be15b203bd4' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ],
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "deepnote_persisted_session": {
   "createdAt": "2024-04-20T17:49:10.133Z"
  },
  "deepnote_full_width": true,
  "deepnote_notebook_id": "76025adab9af4a4fb451a04a4bf44042",
  "deepnote_execution_queue": [],
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 }
}
